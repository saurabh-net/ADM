i'm here today representing a team of artists and technologists and filmmakers that worked together on a remarkable film project for the last four years
and along the way they created a breakthrough in computer visualization so i want to show you a clip of the film now hopefully it won 't stutter and if we did our jobs well you won 't know that we were even involved more
more if i told
if i told need to be
need to be you
you along with
along with i felt pretty good
that was a clip from the curious case of benjamin button many of you maybe you've seen it or you've heard of the story but what you might not know is that for nearly the first hour of the film
the main character benjamin button who 's played by brad pitt is completely computer generated from the neck up
now there's no use of prosthetic makeup or photography of brad superimposed over another actor 's body we've created a completely digital human head
so i'd like to start with a little bit of history on the project this is based on an f scott fitzgerald short story it's about a man who 's born old and lives his life
in reverse now this movie has floated around hollywood for well over half a century and we first got involved with the project in the early nineties with ron howard as the director we took a lot of meetings and we seriously considered it but at the time we had to throw in the towel
it was deemed impossible it was beyond the technology of the day to depict a man aging backwards the human form in particular the human head has been considered the holy grail of our industry
the project came back to us about a decade later and this time with a director named david fincher now fincher is an interesting guy
david is fearless of technology and he is absolutely tenacious and david won 't take no and david believed like we do in the visual effects industry that anything is possible
and he threw a challenge at us he wanted the main character of the film to be played from the cradle to the grave by one actor it happened to be this guy
we went through a process of elimination and a process of discovery with david and we ruled out of course swapping actors that was one idea that we would have
so we decided to cast a series of little people that would play the different bodies of benjamin at the different increments of his life
and that we would in fact create a computer generated version of brad 's head aged to appear as benjamin and attach that to the body of the real actor
sounded great of course this was the holy grail of our industry and the fact that this guy is a global icon didn't help
either because i'm sure if any of you ever stand in line at the grocery store you know we see his face constantly so there really was no tolerable margin of error
but we used lots of cheats and shortcuts we basically put something together to get through the meeting i'll roll that for you now this was the first test for benjamin button and in here you can see that's a computer generated head it's pretty good attached to the body of an actor
and it worked and it gave the studio great relief after many years of starts and stops on this project and making that tough decision
they finally decided to greenlight the movie and i can remember actually when i got the phone call to congratulate us to say the movie was a go i actually threw up
this is some tough stuff so we started to have early team meetings and we got everybody together and it was really more like therapy in the beginning
we really felt like we were in a kind of a twelve step program and of course the first step is admit you've got a problem
so we had a big problem we didn't know how we were going to do this but we did know one thing being from the visual effects industry we with david believed that we now had enough time enough resources and god we hoped we had enough money
we needed to make brad look a lot older we needed to age him forty five years or so and we also needed to make sure that we could take brad 's
a character that could hold up under really all conditions he needed to be able to walk in broad daylight at nighttime under candlelight
not all at the same time but he had to you know do all of those things and the work had to hold up for almost the first hour of the movie we did about three hundred and twenty five shots
so we needed a system that would allow benjamin to do everything a human being can do
and we realized that there was a giant chasm between the state of the art of technology in two thousand and four and where we needed it to be so we focused on motion capture i'm sure many of you have seen motion capture
and instead of using cameras there's infrared sensors around a volume and those infrared sensors track the three dimensional position of those markers in real time and then animators can take the data of the motion of those markers and apply them to a computer generated character you can see the
a pretty crappy performance that's not terribly compelling and what we realized was that what we needed was the information that was going on between the markers we
the technology of the day the status quo the state of the art so we aborted using motion capture and we were now well out of our comfort zone and in uncharted territory so
we were left with this idea that we ended up calling technology stew we started to look out in other fields and the idea was that we were going to find
nuggets or gems of technology that come from other industries like medical imaging the video game space and re appropriate them and we had to create kind of a sauce and the sauce was
code in software that we'd written to allow these disparate pieces of technology to come together and work as one initially we came across some remarkable research done by a gentleman named doctor paul ekman in the early seventies he believed
could in fact catalog the human face and he came up with this idea of facial action coding system he believed that there were seventy
basic poses or shapes of the human face and that from those basic poses or shapes of the face they can be combined to create infinite possibilities of everything the human face is capable of doing and of course
these transcend age race culture gender so this became the foundation of our research as we went forward and then we came across some remarkable technology
called contour and here you can see a subject having phosphorus makeup stippled on her face and now what we're looking at is really creating a surface capture as opposed to a marker capture the subject stands in front of a computer array of cameras and those cameras can
frame by frame reconstruct geometry of exactly what the subject 's doing at the moment so effectively you get three d data in real time of the subject and if you look in a comparison on the left
we see what volumetric data gives us and on the right you see what markers give us so clearly we were in a substantially better place for this
the early days of this technology and it wasn't really proven yet but we measure complexity and fidelity of data in terms of polygonal count and so
on the left we were seeing one hundred thousand polygons we could go up into the millions of polygons it seemed to be infinite this was when we had our
this was the breakthrough this is when we're like ok we're going to be ok this is actually going to work and the a ha was what if we could take brad pitt and we could put brad
in this device and use this contour process and we could stipple on this phosphorescent makeup and put him under the black lights and we could in fact
scan him in real time performing ekman 's facs poses right so effectively we ended up with a three d database of everything brad pitt 's face is capable of doing
from there we actually carved up those faces into smaller pieces and components of his face so we ended up with literally thousands and thousands and thousands of shapes
a complete database of all possibilities that his face is capable of doing now that's great except we had him at age forty four we need to put another forty years on him at this point we brought in
rick baker and rick is one of the great makeup and special effects gurus of our industry and we also brought in a gentleman named kazu tsuji and kazu tsuji is one of the great photoreal sculptors of our time and we commissioned them to make a maquette
or a bust of benjamin so in the spirit of the great unveiling i had to do this i had to unveil something so this is
we created three of these there's ben eighty there's ben seventy there's ben sixty and this really became the template of moving forward now this was made from a life cast of brad so in fact
and so now we had three age increments of benjamin in the computer but we needed to get a database of him doing more than that we went through this process then called retargeting
this is brad doing one of the ekman facs poses and here 's the resulting data that comes from that the model that comes from that and retargeting is the process of transposing
that data onto another model and because the life cast or the bust the maquette of benjamin was made from brad we could transpose the data
of brad at forty four onto brad at eighty seven so now we had a three d database of everything brad pitt 's face can do at age eighty seven in his seventies and in his sixties next we had to go into the shooting process so
all that's going on we're down in new orleans and locations around the world and we shot our body actors and we shot them wearing blue hoods so this is the gentleman playing benjamin
the blue hoods helped us with two things one we could easily erase their heads and we also put tracking markers on their heads so we could recreate the camera motion and the lens optics from the set
but now we needed to get brad 's performance to drive our virtual benjamin and so we edited the footage that was shot on location with the rest of the cast and the
body actors and about six months later we brought brad onto a sound stage in los angeles and he watched on the screen
from there we went into a process called image analysis and so here you can see again the chosen take and we are seeing now that data being transposed on to ben eighty seven
and so what's interesting about this is we used something called image analysis which is taking timings from different components of benjamin's face and so we could choose say his left eyebrow and the software would tell us that well
in frame fourteen the left eyebrow begins to move from here to here and it concludes moving in frame thirty two and so we could choose numbers of positions on the face to pull that data from and then the sauce i talked about with our technology stew that secret sauce
was effectively software that allowed us to match the performance footage of brad in live action with our database of aged benjamin the facs shapes that we had on a frame by frame basis we could actually reconstruct
a three d head that exactly matched the performance of brad so this was how the finished shot appeared in the film and here you can see the body actor
next section here i'm going to just blast through this because we could do a whole tedtalk on the next several slides
to create a lighting system so really a big part of our processes were creating a lighting environment for every single location that benjamin had to appear so that
we could put ben 's head into any scene and it would exactly match the lighting that's on the other actors in the real world we also had to create an eye system
we found the old adage you know the eyes are the window to the soul absolutely true so the key here was to keep everybody looking in ben 's eyes
and if you could feel the warmth and feel the humanity and feel his intent coming through the eyes then we would succeed so we had one person focused on the eye system for almost
skin displacement another big deal the skin had to be absolutely accurate and he 's also in an old age home he 's in a nursing home around other old people so he had to look
so effectively we created a digital puppet that brad pitt could operate with his own face there were no animators necessary to come in and interpret behavior
or enhance his performance there was something that we encountered though that we ended up calling the digital botox effect so as things went through this process
happy smile or a frustrated smile so it did take humans to kind of push it one way or another but we ended up calling the entire process and all the technology emotion capture as opposed to just motion capture take another look but
how to create a digital human in eighteen minutes really
hundred and fifty five people over two years and we didn't even talk about sixty hairstyles and an all digital haircut but that is benjamin thank you
